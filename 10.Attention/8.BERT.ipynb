{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Bert(Bidirectional Encoder Representation from Transformers) 是个只有**双向编码器**的 Transformer，虽然结构很简单，但效果很好\n",
    "分为两个版本：\n",
    "- Base: #blocks 12, hidden size 768,    #heads 12,  #parameters 110M\n",
    "- Large:#blocks 24, hidden size 1024,   #heads 16,  #parameters 340M\n",
    "\n",
    "创新点：\n",
    "- 输入\n",
    "- Loss 函数\n",
    "\n",
    "<cls> 表示句子的分类，<sep> 表示两句话之间的断句符号\n",
    "\n",
    "### 训练任务1：带掩码的语言模型\n",
    "Bert 之所以是双向的，是因为它不需要预测未来，只做完形填空。\n",
    "带掩码的语言模型每次随机（15%概率)将一些词元换成<mask>\n",
    "因为微调任务中不出现<mask>\n",
    "- 80%概率下，将选中的词元变成<mask>\n",
    "- 10%概率下换成一个随机词元\n",
    "- 10%概率下保持原有的词元\n",
    "\n",
    "目的是不要看到 mask 就预测\n",
    "\n",
    "### 训练任务2：下一句子预测\n",
    "- 预测一个句子对中两个句子是不是相邻\n",
    ">每次给出一对句子，预测句子在原始数据中是不是相邻的。\n",
    "\n",
    "- 因此，在训练样本中：\n",
    "    - 50% 概率选择**相邻**句子对：<cls>this movie is great<Sep>i like it <sep>\n",
    "    - 50% 概率选择**随机**句子对：<cls>this movie is great<Sep>hello world<sep>\n",
    "\n",
    "### 总结\n",
    "- BERT针对微调设计\n",
    "- 基于Transformer的编码器做了如下修改\n",
    "    - 模型更大，训川练数据更多\n",
    "    - 输入句子对，片段嵌入，可学习的位置编码\n",
    "- 训练时使用两个任务：\n",
    "    - 带掩码的语言模型\n",
    "    - 下一个句子预测"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bert 模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-05T07:48:41.311895200Z",
     "start_time": "2023-07-05T07:48:18.249273600Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. 输入表示\n",
    "NLP 有些任务（如情感分析）以单个文本作为输入，而有些任务（如自然语言推断）以一对文本序列作为输入。bert 对此进行了明确的区分。\n",
    "- 输入为单文本时，输入序列为 \\<cls> + 文本序列(标记化表示)$e_A$ + \\<sep>。\n",
    "- 输入为文本对时，输入序列为 \\<cls> + 第一个文本序列的标记$e_A$ + \\<sep> + 第二个文本序列标记$e_B$ + \\<sep>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_tokens_and_segments(tokens_a, tokens_b=None):\n",
    "    \"\"\"获取输入序列的词元及其片段索引\"\"\"\n",
    "    tokens = ['<cls>'] + tokens_a + ['<sep>']\n",
    "    # 0和1分别标记片段A和B\n",
    "    segments = [0] * (len(tokens_a) + 2)\n",
    "    if tokens_b is not None:\n",
    "        tokens += tokens_b + ['<sep>']\n",
    "        segments += [1] * (len(tokens_b) + 1)\n",
    "    # 返回的是一个单词数组，及等大的标记数组\n",
    "    return tokens, segments"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T08:20:50.236444300Z",
     "start_time": "2023-07-05T08:20:50.167450200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "['<cls>', 'A', 'A', 'A', '<sep>']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T08:16:26.557358100Z",
     "start_time": "2023-07-05T08:16:26.463745900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bert 数据"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bert 训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## QA"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
