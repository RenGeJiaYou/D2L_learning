{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 0. 前置知识\n",
    "### (1)残差块。\n",
    "结构上，让输入数据**跨层**更快地向前传播。\n",
    "理论上，让每个附加层都应该更容易地**包含原始函数**作为其元素之一。\n",
    "其优势是能拟合出更优的解，更容易降低训练误差。\n",
    "### (2)批量规范化。\n",
    "##### 待解决的问题\n",
    "网络层数一多(形如 x → l1 → l2 → l3 → ... → ln → loss 函数)，规范化就不可避免。因为损失函数在最后层，反向传播时后面的层训练的比较快；而前面的层训练较慢。前面的层一变化，后面所有都得跟着变。导致后面的层重新学习了多次。最终导致收敛变慢。批量规范化，就是希望**前面层改变时，后面的层不必重新学**，以**加速收敛**速度，以前的学习率可能是0.01，现在可设lr=0.1。\n",
    "\n",
    "##### 用在哪里\n",
    "- 可学习的参数为 $\\gamma$和$\\beta$\n",
    "- 作用在\n",
    "    - 全连接层和卷积层的输出上，激活函数前\n",
    "    - 全连接层和卷积层的输入上\n",
    "- 对全连接层，作用在特征维\n",
    "- 对于卷积层，作用在通道维\n",
    "\n",
    "##### 具体在做什么\n",
    "理论还不能解释，深度学习的工程是走在理论前面的。\n",
    "- 批量归一化**固定**小批量中的**均值**和**方差**，然后学习出适合的偏移和缩放\n",
    "- 可以加速收敛速度，但一般不改变模型精度\n",
    "\n",
    "### (3)Embedding\n",
    "将字词变成向量，两个近义词有更近的向量距离。\n",
    "Embedding层，在某种程度上，就是用来降维的，降维的原理就是**矩阵乘法**。\n",
    "假如我们有一个(10W,10W)的矩阵，用它乘上一个(10W,20)的矩阵，我们可以把它降到(10W,20)，瞬间量级降了10W/20=5000倍"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. 模型\n",
    "采用的注意力评分函数是缩放点积评分。\n",
    "### (1) 编码器\n",
    "编码器是由多个相同的层叠加而成的，每个层都有两个子层 sublayer:\n",
    "- 自注意力层\n",
    "- 基于位置的前馈网络\n",
    "\n",
    "编码器在计算自注意力时，查询、键和值都来自前一个编码器层的输出。\n",
    "因为采用了残差连接，要求输入的$X$在流经网络时尺寸不得发生变化。即对于序列中任何位置的任何输入\n",
    "$x \\in \\mathbb{R}^d$，都要求满足$sublayer(x) \\in \\mathbb{R}^d$，以便残差连接满足$$x + sublayer(x) \\in \\mathbb{R}^d$$。\n",
    "\n",
    "在残差连接的加法计算之后，紧接着应用层规范化(layer normalization)\n",
    "\n",
    "### (2) 解码器\n",
    "\n",
    "第一个遮蔽多头注意力 sublayer 使用遮蔽矩阵，要求解码器中的每个位置只能考虑该位置之前的所有位置，确保预测仅依赖于已生成的输出词元。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T07:34:45.363852100Z",
     "start_time": "2023-07-02T07:34:45.340914300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. 基于位置的前馈网络\n",
    "对序列中的所有位置的表示进行变换时使用的是同一个多层感知机（MLP）\n",
    "\n",
    "输入 $x$: (batch_size,num_step,num_hidden)\n",
    "通过一个两层的感知机: (num_hidden,num_hidden,num_outputs),转为\n",
    "输出: (batch_size,num_step,num_outputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    \"\"\"基于位置的前馈网络\"\"\"\n",
    "\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, fnn_num_outputs, **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, fnn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T07:35:09.904329800Z",
     "start_time": "2023-07-02T07:35:09.889327700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "举例：验证基于位置的前馈网络的数据流转"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3, 8])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn = PositionWiseFFN(4, 4, 8)\n",
    "ffn.eval()\n",
    "# 传入 1 个 batch,每个 batch 有 2 个时间步（也可称为子序列），每个时间步长度=4=ffn_num_input\n",
    "ffn(torch.ones(2, 3, 4)).shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T07:38:27.227783900Z",
     "start_time": "2023-07-02T07:38:27.173238900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. 残差连接和层规范化（add & norm）\n",
    "在NLP中（输入通常是变长序列）批量规范化通常不如层规范化的效果好。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer norm: tensor([[-1.0000,  1.0000],\n",
      "        [-1.0000,  1.0000]], grad_fn=<NativeLayerNormBackward0>) \n",
      "batch norm: tensor([[-1.0000, -1.0000],\n",
      "        [ 1.0000,  1.0000]], grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = nn.LayerNorm(2)  # 每个 batch 单独进行归一化\n",
    "bn = nn.BatchNorm1d(2)  # 所有 batch 一起进行归一化\n",
    "\n",
    "X = torch.tensor([[1, 2], [2, 3]], dtype=torch.float32)\n",
    "# 在训练模式下计算X的均值和方差\n",
    "print('layer norm:', ln(X), '\\nbatch norm:', bn(X))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T08:31:11.604274400Z",
     "start_time": "2023-07-02T08:31:11.490603100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用残差连接和层规范化来实现AddNorm类"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    \"\"\"残差连接后进行层规范化\"\"\"\n",
    "\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)  # dropout(Y) + X 即残差操作，ln()进行规范化"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T09:46:54.780944Z",
     "start_time": "2023-07-02T09:46:54.740920900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "残差连接要求两个输入的形状相同，加法操作后输出张量的形状也一致。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3, 4])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_norm = AddNorm([3, 4], 0.5)\n",
    "add_norm.eval()\n",
    "add_norm(torch.ones((2, 3, 4)), torch.ones((2, 3, 4))).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T09:46:55.853769700Z",
     "start_time": "2023-07-02T09:46:55.780769500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.编码器\n",
    "编码器的两个 `sublayer` 已经定义完成，开始构造编码器的单层组件"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"Transformer 编码器块\"\"\"\n",
    "\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, dropout,\n",
    "                 use_bias=False, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.attention = d2l.MultiHeadAttention(key_size, query_size, value_size, num_hiddens,\n",
    "                                                num_heads, dropout, use_bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, ffn_num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
    "        return self.addnorm2(Y, self.ffn(Y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T11:17:28.883359800Z",
     "start_time": "2023-07-02T11:17:28.858353700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "编码器中的任何层都不会改变其输入的形状。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 100, 24])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((2, 100, 24))\n",
    "valid_lens = torch.tensor([3, 2])\n",
    "encoder_blk = EncoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5)\n",
    "encoder_blk.eval()\n",
    "encoder_blk(X, valid_lens).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T11:17:29.797814400Z",
     "start_time": "2023-07-02T11:17:29.763815800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "class TransformerEncoder(d2l.Encoder):\n",
    "    \"\"\"Transformer编码器\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)  # 每个嵌入向量的大小 = 隐藏层单元数\n",
    "        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blocks = nn.Sequential()\n",
    "\n",
    "        # 编码器第 i 层自注意力接受的查询、键和值都来自第 i-1 层的自注意力的输出\n",
    "        for i in num_layers:\n",
    "            self.blocks.add_module(\"block\" + str(i),\n",
    "                                   EncoderBlock(key_size, query_size, value_size, num_hiddens, norm_shape,\n",
    "                                                ffn_num_input, ffn_num_hiddens, num_heads, dropout, use_bias))\n",
    "\n",
    "    def forward(self, X, valid_lens, *args):\n",
    "        # 因为位置编码值在-1和1之间，\n",
    "        # 因此嵌入值乘以嵌入维度的平方根进行缩放，\n",
    "        # 然后再与位置编码相加。\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self.attention_weights = [None] * len(self.blocks)\n",
    "        for i, blk in enumerate(self.blocks):\n",
    "            X = blk(X, valid_lens)\n",
    "            self.attention_weights[i] = blk.attention.attention.attention_weights\n",
    "        return X\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T12:17:07.035749100Z",
     "start_time": "2023-07-02T12:17:06.952782100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "下面我们指定了超参数来创建一个$2$层的Transformer编码器。\n",
    "Transformer编码器输出的形状是（批量大小，时间步数目，num_hiddens）。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 100, 24])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = TransformerEncoder(\n",
    "    200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2, 0.5)\n",
    "encoder.eval()\n",
    "encoder(torch.ones((2, 100), dtype=torch.long), valid_lens).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T12:17:08.198776300Z",
     "start_time": "2023-07-02T12:17:08.040746Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "关于 nn.Embedding()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0.9862,  1.1006,  0.9881],\n         [ 2.0816, -1.8696, -1.1936],\n         [ 0.4373, -0.8299, -0.3389],\n         [ 0.5716,  1.4253,  0.3239],\n         [ 1.1779, -2.2216,  1.4105]],\n\n        [[ 2.0816, -1.8696, -1.1936],\n         [ 2.0816, -1.8696, -1.1936],\n         [ 0.4373, -0.8299, -0.3389],\n         [ 0.5716,  1.4253,  0.3239],\n         [ 1.1779, -2.2216,  1.4105]]], grad_fn=<EmbeddingBackward0>)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @param:   num_embeddings      嵌入词表的尺寸\n",
    "# @param:   embedding_dim       要求每个嵌入向量的size，transformer 要求为 3\n",
    "embedding = nn.Embedding(10, 3)\n",
    "\n",
    "# a batch of 2 samples of 4 indices each\n",
    "i = torch.LongTensor([[1, 2, 3, 4, 5], [2, 2, 3, 4, 5]])\n",
    "embedding(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T12:01:10.422405400Z",
     "start_time": "2023-07-02T12:01:10.390405100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. 解码器\n",
    "由多个相同的层组成。\n",
    "在DecoderBlock 类中实现的每个层包含了三个子层：解码器自注意力、“编码器-解码器”注意力和基于位置的前馈网络。\n",
    "这些子层也都被 Addnorm 层规范化围绕。\n",
    "\n",
    "参数dec_valid_lens 确保任何查询都只会与解码器中所有**已经生成词元**的位置（即直到该查询位置为止）进行注意力计算。\n",
    "> 关于序列到序列模型（sequence-to-sequence model），在训练阶段，其输出序列的所有位置（时间步）的词元都是已知的；然而，在预测阶段，其输出序列的词元是逐个生成的。因此，在任何解码器时间步中，**只有生成的词元才能用于解码器的自注意力计算中**。为了在解码器中保留自回归的属性，其掩蔽自注意力设定了参数dec_valid_lens，以便任何查询都只会与解码器中所有已经生成词元的位置（即直到该查询位置为止）进行注意力计算。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"解码器中第i个块\"\"\"\n",
    "\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, i, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.i = i  # 标识当前第 i 个 block\n",
    "        self.attention1 = d2l.MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "        self.attention2 = d2l.MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        # 编码器的输入由 state 赋予，是 TransformerDecoder 类的成员变量\n",
    "        enc_output, enc_valid_lens = state[0], state[1]\n",
    "\n",
    "        # 训练阶段，输出序列的所有词元都在同一时间处理，\n",
    "        # 因此state[2][self.i]初始化为None。\n",
    "        # 预测阶段，输出序列是通过词元一个接着一个解码的，\n",
    "        # 因此state[2][self.i]包含着直到当前时间步第i个块解码的输出表示\n",
    "        if state[2][self.i] is None:\n",
    "            key_values = X\n",
    "        else:\n",
    "            key_values = torch.cat((state[2][self.i], X), dim=1)\n",
    "        state[2][self.i] = key_values\n",
    "\n",
    "        if self.training:\n",
    "            batch_size, num_step, _ = X.shape\n",
    "            # dec_valid_lens的开头:(batch_size,num_steps),\n",
    "            # 其中每一行是[1,2,...,num_steps]\n",
    "            dec_valid_lens"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
